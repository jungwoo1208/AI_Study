{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7blekoec7lWnW4psBtOgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jungwoo1208/AI_Study/blob/main/xor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mRpOhfS9HyZC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(128)\n",
        "if device.type == 'cuda':\n",
        "    torch.cuda.manual_seed_all(128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eZiXxsjH70r",
        "outputId": "cba62969-e503-4b6c-9ee0-c9abeb66abc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
        "y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)"
      ],
      "metadata": {
        "id": "8jaIuOVpIIuh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2,10,bias=True),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,10,bias=True),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,10,bias=True),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,1,bias=True),\n",
        "    nn.Sigmoid()\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "b8qaAIusIYKo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1)\n",
        "epochs = 10001"
      ],
      "metadata": {
        "id": "syO5eB9uIieP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  hypothesis = model(x)\n",
        "  cost = criterion(hypothesis,y)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    print(epoch,cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zp121veIsXe",
        "outputId": "cde2eee7-9d5f-4b24-8cfa-56a9f7c92c4b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.7287128567695618\n",
            "100 0.6931551098823547\n",
            "200 0.6931539177894592\n",
            "300 0.6931527853012085\n",
            "400 0.6931516528129578\n",
            "500 0.693150520324707\n",
            "600 0.6931494474411011\n",
            "700 0.6931483745574951\n",
            "800 0.6931473612785339\n",
            "900 0.693146288394928\n",
            "1000 0.693145215511322\n",
            "1100 0.6931440830230713\n",
            "1200 0.6931430101394653\n",
            "1300 0.6931419372558594\n",
            "1400 0.6931406855583191\n",
            "1500 0.6931395530700684\n",
            "1600 0.6931382417678833\n",
            "1700 0.6931370496749878\n",
            "1800 0.6931356191635132\n",
            "1900 0.6931342482566833\n",
            "2000 0.693132758140564\n",
            "2100 0.6931312084197998\n",
            "2200 0.6931295990943909\n",
            "2300 0.6931278109550476\n",
            "2400 0.6931259632110596\n",
            "2500 0.693123996257782\n",
            "2600 0.6931217312812805\n",
            "2700 0.6931194067001343\n",
            "2800 0.6931169033050537\n",
            "2900 0.6931141018867493\n",
            "3000 0.6931110620498657\n",
            "3100 0.6931077241897583\n",
            "3200 0.693104088306427\n",
            "3300 0.6930999755859375\n",
            "3400 0.6930954456329346\n",
            "3500 0.6930903196334839\n",
            "3600 0.6930844783782959\n",
            "3700 0.6930779218673706\n",
            "3800 0.6930704712867737\n",
            "3900 0.693061888217926\n",
            "4000 0.6930519342422485\n",
            "4100 0.6930403709411621\n",
            "4200 0.693026602268219\n",
            "4300 0.6930102109909058\n",
            "4400 0.6929903626441956\n",
            "4500 0.692966103553772\n",
            "4600 0.6929359436035156\n",
            "4700 0.6928977370262146\n",
            "4800 0.6928482055664062\n",
            "4900 0.6927822828292847\n",
            "5000 0.6926918625831604\n",
            "5100 0.6925628185272217\n",
            "5200 0.6923693418502808\n",
            "5300 0.6920602321624756\n",
            "5400 0.6915221810340881\n",
            "5500 0.6904671788215637\n",
            "5600 0.6879986524581909\n",
            "5700 0.6802940368652344\n",
            "5800 0.642996072769165\n",
            "5900 0.5362830758094788\n",
            "6000 0.33827894926071167\n",
            "6100 0.012614881619811058\n",
            "6200 0.005710823927074671\n",
            "6300 0.0035647994372993708\n",
            "6400 0.0025518720503896475\n",
            "6500 0.001970726763829589\n",
            "6600 0.0015968687366694212\n",
            "6700 0.001337586436420679\n",
            "6800 0.0011478627566248178\n",
            "6900 0.0010033734142780304\n",
            "7000 0.0008899291278794408\n",
            "7100 0.0007986508426256478\n",
            "7200 0.0007236482342705131\n",
            "7300 0.0006609961856156588\n",
            "7400 0.0006080014863982797\n",
            "7500 0.000562510802410543\n",
            "7600 0.0005231335526332259\n",
            "7700 0.0004887243267148733\n",
            "7800 0.00045838626101613045\n",
            "7900 0.0004314651887398213\n",
            "8000 0.00040742417331784964\n",
            "8100 0.00038582939305342734\n",
            "8200 0.0003663254901766777\n",
            "8300 0.00034861016320064664\n",
            "8400 0.00033248079125769436\n",
            "8500 0.00031774607487022877\n",
            "8600 0.00030417327070608735\n",
            "8700 0.00029172562062740326\n",
            "8800 0.000280163309071213\n",
            "8900 0.00026949815219268203\n",
            "9000 0.0002595798869151622\n",
            "9100 0.0002503133728168905\n",
            "9200 0.00024167705851141363\n",
            "9300 0.00023361387138720602\n",
            "9400 0.0002260387991555035\n",
            "9500 0.00021892953373026103\n",
            "9600 0.00021220730559434742\n",
            "9700 0.00020591323846019804\n",
            "9800 0.0001999430824071169\n",
            "9900 0.00019432860426604748\n",
            "10000 0.00018899681163020432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  hypothesis = model(x)\n",
        "  predicted = (hypothesis > 0.5).float()\n",
        "  accuracy = (predicted == y).float().mean()\n",
        "  print('Hypothesis: ', hypothesis.detach().cpu().numpy())\n",
        "  print('Predicted: ', predicted.detach().cpu().numpy())\n",
        "  print('Y: ', y.cpu().numpy())\n",
        "  print('Accuracy: ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OQYkCvVI0Ph",
        "outputId": "f3fbf7b1-04da-416b-eeb4-192051b35ee7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hypothesis:  [[1.6460476e-04]\n",
            " [9.9983537e-01]\n",
            " [9.9978524e-01]\n",
            " [2.1170361e-04]]\n",
            "Predicted:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Y:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Accuracy:  1.0\n"
          ]
        }
      ]
    }
  ]
}