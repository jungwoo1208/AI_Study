{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKPj5m1xagNNqXWDEpEhvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jungwoo1208/AI_Study/blob/main/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#문자 단위"
      ],
      "metadata": {
        "id": "N2Zb-nNjbT-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VflS9SvebMA-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = 'apple'\n",
        "label_str = 'pple!'\n",
        "char_vocab = sorted(list(set(input_str+label_str)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('문자 집합 사이즈 :{}'.format(vocab_size))\n",
        "print ('문자 집합 : ', char_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb7KX1EZbdTF",
        "outputId": "0781b7e1-d1f3-4bf3-a828-53d5869d61dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 사이즈 :5\n",
            "문자 집합 :  ['!', 'a', 'e', 'l', 'p']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = vocab_size\n",
        "hidden_size = 5\n",
        "output_size = 5\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "c9pcHXARbrXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg59ANI4bvu-",
        "outputId": "4d8816fc-7735-4b84-c065-d28ce838df6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [char_to_index[c] for c in input_str]\n",
        "y_data = [char_to_index[c] for c in label_str]\n",
        "print(x_data)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbW3Iyjhbypk",
        "outputId": "5e8b57ee-d9a8-4676-f9f9-6919340d189b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 4, 3, 2]\n",
            "[4, 4, 3, 2, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [x_data]\n",
        "y_data = [y_data]"
      ],
      "metadata": {
        "id": "nwvjslOyb2sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = [np.eye(vocab_size)[x] for x in x_data]"
      ],
      "metadata": {
        "id": "5IeqOVKXb9Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.FloatTensor(x_one_hot)\n",
        "y=torch.LongTensor(y_data)"
      ],
      "metadata": {
        "id": "j8AbWCTxb_Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "uEhWw7PocDb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "-5zHlnntcXVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(x)"
      ],
      "metadata": {
        "id": "t0lS6aZ3ccOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "H-t_AjAfcfWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(x)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    result = outputs.data.numpy().argmax(axis=2)\n",
        "    result_str = ''.join([char_vocab[c] for c in np.squeeze(result)])\n",
        "    print(i, \"loss: \", loss.item(), \"prediction: \", result, \"true Y: \", y_data, \"prediction str: \", result_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5l51_vRcnkD",
        "outputId": "53830b89-3bba-4780-f1cc-eed3331e4973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss:  1.612802505493164 prediction:  [[4 4 4 1 4]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppap\n",
            "1 loss:  1.377203106880188 prediction:  [[4 4 4 0 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  ppp!!\n",
            "2 loss:  1.151977300643921 prediction:  [[4 4 4 3 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppl!\n",
            "3 loss:  0.948016345500946 prediction:  [[4 4 4 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppe!\n",
            "4 loss:  0.7293846607208252 prediction:  [[4 4 4 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppe!\n",
            "5 loss:  0.5560047030448914 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "6 loss:  0.4022025465965271 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "7 loss:  0.2791253328323364 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "8 loss:  0.2001728117465973 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "9 loss:  0.1359129101037979 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "10 loss:  0.0902300700545311 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "11 loss:  0.06370805203914642 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "12 loss:  0.0470871701836586 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "13 loss:  0.035766273736953735 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "14 loss:  0.027915626764297485 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "15 loss:  0.022303054109215736 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "16 loss:  0.018085887655615807 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "17 loss:  0.014770960435271263 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "18 loss:  0.012101639062166214 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "19 loss:  0.0099457623437047 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "20 loss:  0.00821945071220398 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "21 loss:  0.006850978825241327 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "22 loss:  0.005773021373897791 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "23 loss:  0.004925094079226255 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "24 loss:  0.004257040563970804 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "25 loss:  0.003729607444256544 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "26 loss:  0.003312154207378626 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "27 loss:  0.0029806955717504025 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "28 loss:  0.002715729409828782 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "29 loss:  0.002500982489436865 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "30 loss:  0.002323217922821641 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "31 loss:  0.0021716286428272724 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "32 loss:  0.002038343343883753 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "33 loss:  0.0019177889917045832 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "34 loss:  0.0018070513615384698 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "35 loss:  0.0017048781737685204 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "36 loss:  0.0016111809527501464 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "37 loss:  0.0015263454988598824 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "38 loss:  0.001450400217436254 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "39 loss:  0.0013833013363182545 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "40 loss:  0.0013243855210021138 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "41 loss:  0.001272702938877046 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "42 loss:  0.0012272559106349945 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "43 loss:  0.0011868312722072005 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "44 loss:  0.0011503823334351182 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "45 loss:  0.0011171475052833557 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "46 loss:  0.0010865319054573774 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "47 loss:  0.0010580826783552766 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "48 loss:  0.0010314668761566281 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "49 loss:  0.0010066836839541793 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "50 loss:  0.0009835431119427085 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "51 loss:  0.0009620209457352757 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "52 loss:  0.0009421886643394828 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "53 loss:  0.0009238081984221935 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "54 loss:  0.0009067842038348317 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "55 loss:  0.0008911885088309646 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "56 loss:  0.0008768303086981177 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "57 loss:  0.0008635672857053578 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "58 loss:  0.0008512799395248294 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "59 loss:  0.0008398258942179382 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "60 loss:  0.0008292050333693624 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "61 loss:  0.0008191553642973304 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "62 loss:  0.0008097008103504777 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "63 loss:  0.0008008176228031516 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "64 loss:  0.0007923153461888433 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "65 loss:  0.0007842654595151544 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "66 loss:  0.000776501081418246 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "67 loss:  0.0007691416540183127 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "68 loss:  0.0007619725074619055 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "69 loss:  0.0007550652953796089 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "70 loss:  0.0007484200177714229 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "71 loss:  0.0007419890025630593 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "72 loss:  0.0007357723079621792 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "73 loss:  0.000729793799109757 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "74 loss:  0.0007239104015752673 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "75 loss:  0.0007182889385148883 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "76 loss:  0.00071278668474406 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "77 loss:  0.0007074272725731134 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "78 loss:  0.0007022107020020485 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "79 loss:  0.0006971370312385261 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "80 loss:  0.0006922063184902072 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "81 loss:  0.0006873945822007954 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "82 loss:  0.0006826543249189854 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "83 loss:  0.0006780332187190652 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "84 loss:  0.0006736025679856539 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "85 loss:  0.0006691957823932171 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "86 loss:  0.0006648366106674075 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "87 loss:  0.0006605965318158269 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "88 loss:  0.000656427931971848 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "89 loss:  0.0006522830808535218 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "90 loss:  0.0006482572061941028 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "91 loss:  0.00064425531309098 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "92 loss:  0.0006403486477211118 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "93 loss:  0.000636465847492218 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "94 loss:  0.0006326544098556042 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "95 loss:  0.0006288668373599648 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "96 loss:  0.0006251982995308936 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "97 loss:  0.0006214820896275342 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "98 loss:  0.0006178850890137255 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "99 loss:  0.0006142879719845951 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_RRN2IJiezQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 더 많은 데이터 학습\n"
      ],
      "metadata": {
        "id": "sEkMS6Zqe1Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "23gStYP9fQc2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence =(\"동해물과 백두산이 마르고 닳도록\"\n",
        "\"하느님이 보우하사 우리나라 만세\"\n",
        "\"무궁화 삼천리 화려강산\"\n",
        "\"대한 사람 대한으로 길이 보전하세\")"
      ],
      "metadata": {
        "id": "STA6iuyKgX_X"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_set= list(set(sentence))\n",
        "char_dic = {c: i for i, c in enumerate(char_set)}"
      ],
      "metadata": {
        "id": "iec8DaYVhuCG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(char_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHWc2kkYh6OO",
        "outputId": "42209f9c-50b0-467b-d13a-c79fe2790ee3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'려': 0, '느': 1, '궁': 2, '나': 3, '무': 4, '르': 5, '물': 6, '람': 7, '산': 8, '리': 9, '도': 10, '강': 11, '우': 12, '닳': 13, '마': 14, '대': 15, '화': 16, ' ': 17, '으': 18, '님': 19, '이': 20, '라': 21, '동': 22, '만': 23, '백': 24, '고': 25, '해': 26, '하': 27, '천': 28, '록': 29, '로': 30, '길': 31, '두': 32, '보': 33, '삼': 34, '세': 35, '과': 36, '한': 37, '전': 38, '사': 39}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic_size = len(char_dic)\n",
        "hidden_size = dic_size\n",
        "squence_length = 10\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "MHE5LLDCiB_9"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data=[]\n",
        "y_data=[]\n",
        "\n",
        "for i in range(0, len(sentence)-squence_length):\n",
        "    x_str = sentence[i:i+squence_length]\n",
        "    y_str = sentence[i+1:i+squence_length+1]\n",
        "    print(i, x_str, '->',y_str)\n",
        "    x_data.append([char_dic[k] for k in x_str])\n",
        "    y_data.append([char_dic[k] for k in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOJapWIqiRBY",
        "outputId": "c266496a-83f6-4e4d-fac0-6ef07ce157df"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 동해물과 백두산이  -> 해물과 백두산이 마\n",
            "1 해물과 백두산이 마 -> 물과 백두산이 마르\n",
            "2 물과 백두산이 마르 -> 과 백두산이 마르고\n",
            "3 과 백두산이 마르고 ->  백두산이 마르고 \n",
            "4  백두산이 마르고  -> 백두산이 마르고 닳\n",
            "5 백두산이 마르고 닳 -> 두산이 마르고 닳도\n",
            "6 두산이 마르고 닳도 -> 산이 마르고 닳도록\n",
            "7 산이 마르고 닳도록 -> 이 마르고 닳도록하\n",
            "8 이 마르고 닳도록하 ->  마르고 닳도록하느\n",
            "9  마르고 닳도록하느 -> 마르고 닳도록하느님\n",
            "10 마르고 닳도록하느님 -> 르고 닳도록하느님이\n",
            "11 르고 닳도록하느님이 -> 고 닳도록하느님이 \n",
            "12 고 닳도록하느님이  ->  닳도록하느님이 보\n",
            "13  닳도록하느님이 보 -> 닳도록하느님이 보우\n",
            "14 닳도록하느님이 보우 -> 도록하느님이 보우하\n",
            "15 도록하느님이 보우하 -> 록하느님이 보우하사\n",
            "16 록하느님이 보우하사 -> 하느님이 보우하사 \n",
            "17 하느님이 보우하사  -> 느님이 보우하사 우\n",
            "18 느님이 보우하사 우 -> 님이 보우하사 우리\n",
            "19 님이 보우하사 우리 -> 이 보우하사 우리나\n",
            "20 이 보우하사 우리나 ->  보우하사 우리나라\n",
            "21  보우하사 우리나라 -> 보우하사 우리나라 \n",
            "22 보우하사 우리나라  -> 우하사 우리나라 만\n",
            "23 우하사 우리나라 만 -> 하사 우리나라 만세\n",
            "24 하사 우리나라 만세 -> 사 우리나라 만세무\n",
            "25 사 우리나라 만세무 ->  우리나라 만세무궁\n",
            "26  우리나라 만세무궁 -> 우리나라 만세무궁화\n",
            "27 우리나라 만세무궁화 -> 리나라 만세무궁화 \n",
            "28 리나라 만세무궁화  -> 나라 만세무궁화 삼\n",
            "29 나라 만세무궁화 삼 -> 라 만세무궁화 삼천\n",
            "30 라 만세무궁화 삼천 ->  만세무궁화 삼천리\n",
            "31  만세무궁화 삼천리 -> 만세무궁화 삼천리 \n",
            "32 만세무궁화 삼천리  -> 세무궁화 삼천리 화\n",
            "33 세무궁화 삼천리 화 -> 무궁화 삼천리 화려\n",
            "34 무궁화 삼천리 화려 -> 궁화 삼천리 화려강\n",
            "35 궁화 삼천리 화려강 -> 화 삼천리 화려강산\n",
            "36 화 삼천리 화려강산 ->  삼천리 화려강산대\n",
            "37  삼천리 화려강산대 -> 삼천리 화려강산대한\n",
            "38 삼천리 화려강산대한 -> 천리 화려강산대한 \n",
            "39 천리 화려강산대한  -> 리 화려강산대한 사\n",
            "40 리 화려강산대한 사 ->  화려강산대한 사람\n",
            "41  화려강산대한 사람 -> 화려강산대한 사람 \n",
            "42 화려강산대한 사람  -> 려강산대한 사람 대\n",
            "43 려강산대한 사람 대 -> 강산대한 사람 대한\n",
            "44 강산대한 사람 대한 -> 산대한 사람 대한으\n",
            "45 산대한 사람 대한으 -> 대한 사람 대한으로\n",
            "46 대한 사람 대한으로 -> 한 사람 대한으로 \n",
            "47 한 사람 대한으로  ->  사람 대한으로 길\n",
            "48  사람 대한으로 길 -> 사람 대한으로 길이\n",
            "49 사람 대한으로 길이 -> 람 대한으로 길이 \n",
            "50 람 대한으로 길이  ->  대한으로 길이 보\n",
            "51  대한으로 길이 보 -> 대한으로 길이 보전\n",
            "52 대한으로 길이 보전 -> 한으로 길이 보전하\n",
            "53 한으로 길이 보전하 -> 으로 길이 보전하세\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_data[0])\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYNINBAYie9z",
        "outputId": "e46143fb-f59c-40a1-8a1d-0933c5f2043b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22, 26, 6, 36, 17, 24, 32, 8, 20, 17]\n",
            "[26, 6, 36, 17, 24, 32, 8, 20, 17, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = [np.eye(dic_size)[x]for x in x_data]\n",
        "x= torch.FloatTensor(x_one_hot)\n",
        "y= torch.LongTensor(y_data)"
      ],
      "metadata": {
        "id": "IKMOgvvvi5kJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self,input_dim,hidden_dim,layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3ytFj4PijMIB"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(dic_size, hidden_size, 2)"
      ],
      "metadata": {
        "id": "c_6R7Q-PjawM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "RO3la-iYjf84"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSmaaXivmfez",
        "outputId": "1de993a3-8030-4bd3-8a3e-4c79ea855e73"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([54, 10, 40])\n",
            "torch.Size([54, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=net(x)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAcUtPnrjtr2",
        "outputId": "3b32eb82-734b-40c6-ef4d-b5219ef83af0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([54, 10, 40])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  optimizer.zero_grad()\n",
        "  outputs = net(x)\n",
        "  # Reshape outputs to (batch_size * sequence_length, dic_size) before calculating loss\n",
        "  loss = criterion(outputs.view(-1, dic_size), y.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # Get predicted indices for each character\n",
        "  results = outputs.argmax(dim=2)\n",
        "  # Reshape to (batch_size, sequence_length)\n",
        "  results = results.view(-1, squence_length)\n",
        "\n",
        "  predict_str = \"\"\n",
        "  for j, result in enumerate(results):\n",
        "    if j == 0:  # For the first sequence, add all predicted characters\n",
        "      predict_str += ''.join([char_set[t] for t in result])\n",
        "    else:  # For subsequent sequences, add only the last predicted character\n",
        "      predict_str += char_set[result[-1]]\n",
        "\n",
        "  print(predict_str)  # Print the predicted string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NjS-2pDjyal",
        "outputId": "e2ea1726-9d1a-446d-86f7-8e52794b3131"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "우라라라라라천라라라라라천라라천천라라라라라라라라천라라라라라라라라라라라라라라라라라라라천라천라천라라라천라라라천라라라라라\n",
            "             리   리     리사리 리       리           리 리     리     리사\n",
            "님하  전사 전동   사사    사  사  사사  사사  사사 사사   사   사  사사 사 사    사사 사사 \n",
            "이 이천대 이록사로 대로로  세 로 고로  로   고  로 무로 로    로로   로 로 로로  화    사 마 \n",
            "  이 마이님이 마님마마마마님사마마마마마마마마화마님마화고마마마마화마마마마화마화마화마마님마화마마마마마마마마마마님마마\n",
            " 화        화 한   한   화                     화              화  화  \n",
            " 느 리  록 람 세  록로리   세  느  느 리  느   로산 하  느  느   람 산 로    로리 로느  \n",
            "       하으만천   르우하궁  하보으 궁 삼   닳만르만궁  보천하나만르   보닳보려  르 한 만르록보   \n",
            "  삼천만세천보  르닳 만르 님  세천만르 보닳보  만 무르무궁  보르사  르무르닳  만  보 천만르무세천만   \n",
            " 사이 사람닳사 사 님  세무하 으 사사 르  사  사 사세하 화 하람하 사람무세   보     하    사 도 \n",
            "무님이 하이 사 사이 사 님 하이   사 사  사이 사  님 사  사 사 하도사이 하 사  사 하하 하이 사 하 \n",
            "무님이 하이 사 마이 사 님 하  이 마이하이 마이 하 하님 마  사 하 화 로이 사 마이 사  로 하이 마이 사\n",
            "무궁이 마이하한 마이  만도록하 강이 삼느하   삼 하 마한 한화 삼람리 화 마이 한 삼느 한한 삼느하이 삼느하사\n",
            "무물이느강이   강이  닳도록이무님  보우하느화 삼 리 마려하 화 마우리 화려만이화  보화  화려만람하   닳하 \n",
            "무물과려강세 이 만르 이닳과화 이 이 보르님이 로르 이 만세 리느 보닳님 닳려대느님이 님이록이느 이 만이 강르님이\n",
            "무하과으만우 이 보르  닳도화 이 이 보우하대 로  이 보우무   대천리 화려대느 이 궁화록대한 대 님이 보우하이\n",
            "무하과으보산하이 보세하 닳도대하화 이 보우하  우리 이 보천하 화 삼천리 화려대산 이 삼산대대한 대 대이 대천하사\n",
            "삼물과 백람고이 보르고궁닳도록하화산이 보천하궁한우리 도 백천무궁화 삼천리 화려강산 이 사람 궁한 대 대이 궁천하사\n",
            "삼물과 백람산이 마세고 대도록하화 이 보우하사 우한 한 보세무궁화 삼천하 화려강산 사 우람 라한 로 만이 사천하사\n",
            "삼물과느백람산이 마세고 닳도이하이님이 보우하사 우  이 보세무궁화 삼천하 화려강산 이 대람 라한 로 길이 사우하사\n",
            "강물과 사람으이 보르고 닳도무하느길이 보르하사 우  이 마세무궁화으삼천하 화려강  이 사람 대한으로 길이 보우하사\n",
            "해물과 백람으이 보르고 닳도록하느님이 보우하사 우리 이 보르무궁화으로천리 화려강람대우 사람 대화으로 길이 보르하사\n",
            "해물과 백두산이 마람고 닳도록하느님이 보우하사 우리 라 만세무궁화으삼천리 화려강람대한 사람 대한으로 길이 보우하사\n",
            "해물과 백두님이 보르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하사\n",
            "해물과록백두님이 마세고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산닳한 사람 대한으로 길이 만우하사\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하사\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하사\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하사\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하사\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하사\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하사\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하사\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보우하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n",
            "해물과 백두산이 마르고 닳도록하느님이 보우하사 우리나라 만세무궁화 삼천리 화려강산대한 사람 대한으로 길이 보전하세\n"
          ]
        }
      ]
    }
  ]
}