{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaCCqxMHkYrAW7ySa86DM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jungwoo1208/AI_Study/blob/main/attention_transrator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6QpnMIXI4Lid"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import zipfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 100000"
      ],
      "metadata": {
        "id": "IfQUpsya4yKY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://www.manythings.org/anki/fra-eng.zip &&unzip -o fra-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-kKBjCj42ji",
        "outputId": "9540b269-be58-4997-b090-8aff7b79f255"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-13 00:14:48--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8143096 (7.8M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.77M  6.02MB/s    in 1.3s    \n",
            "\n",
            "2025-08-13 00:14:50 (6.02 MB/s) - ‘fra-eng.zip’ saved [8143096/8143096]\n",
            "\n",
            "Archive:  fra-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
      ],
      "metadata": {
        "id": "JfruYlNar0oj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sent):\n",
        "\n",
        "  sent = unicode_to_ascii(sent.lower())\n",
        "  sent= re.sub(r\"([?.!,?`])\",r\" \\1\",sent)\n",
        "  sent= re.sub(r\"[^a-zA-Z!,?`]+\",\" \",sent)\n",
        "  sent = re.sub(r\"\\s+\", \" \",sent)\n",
        "\n",
        "  return sent"
      ],
      "metadata": {
        "id": "_Y5lsv4t5R8Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data():\n",
        "    encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "    with open(\"fra.txt\", \"r\") as lines:\n",
        "        for i, line in enumerate(lines):\n",
        "            src_line, tar_line, _ = line.strip().split(\"\\t\")\n",
        "\n",
        "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "            tar_line = preprocess_sentence(tar_line)\n",
        "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "            encoder_input.append(src_line)\n",
        "            decoder_input.append(tar_line_in)\n",
        "            decoder_target.append(tar_line_out)\n",
        "\n",
        "    return encoder_input, decoder_input, decoder_target"
      ],
      "metadata": {
        "id": "KlGOUuk96Iz6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()"
      ],
      "metadata": {
        "id": "Z1faSFoK7ssp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(sents):\n",
        "    word_list = []\n",
        "    for sent in sents:\n",
        "        for word in sent:\n",
        "            word_list.append(word)\n",
        "    word_counts = Counter(word_list)\n",
        "    vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    word_to_index = {}\n",
        "    word_to_index[\"<PAD>\"] = 0\n",
        "    word_to_index[\"<UNK>\"] = 1\n",
        "\n",
        "    for index, word in enumerate(vocab):\n",
        "        word_to_index[word] = index + 2\n",
        "\n",
        "    return word_to_index"
      ],
      "metadata": {
        "id": "zV8v3tI08X4v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = build_vocab(sents_en_in)\n",
        "tar_vocab = build_vocab(sents_fra_in+ sents_fra_out)\n",
        "\n",
        "src_vocab_size = len(src_vocab)\n",
        "tar_vocab_size = len(tar_vocab)\n",
        "\n",
        "print(src_vocab_size)\n",
        "print(tar_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUOJ2NVH85zi",
        "outputId": "dd6ba44e-3da9-4a11-fe7e-f028b9c003e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16331\n",
            "26065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src ={v: k for k, v in src_vocab.items()}\n",
        "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
        "\n",
        "def texts_to_sequences(sents,word_to_index):\n",
        "  encoded_X_data =[]\n",
        "  for sent in tqdm(sents):\n",
        "    index_sequences =[]\n",
        "    for word in sent:\n",
        "      try:\n",
        "        index_sequences.append(word_to_index[word])\n",
        "      except KeyError:\n",
        "        index_sequences.append(word_to_index[\"<UNK>\"])\n",
        "    encoded_X_data.append(index_sequences)\n",
        "  return encoded_X_data\n"
      ],
      "metadata": {
        "id": "ylj8ZzeS9Mmp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n",
        "decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n",
        "decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)\n",
        "\n",
        "for i, (item1,item2) in zip(range(5), zip(sents_en_in, encoder_input)):\n",
        "  print(f\"index:{i}   {item1} -> {item2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGh9x3Eq92iR",
        "outputId": "c25b4673-6850-403b-b76f-2192c200c1fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237838/237838 [00:00<00:00, 263405.58it/s]\n",
            "100%|██████████| 237838/237838 [00:00<00:00, 268379.25it/s]\n",
            "100%|██████████| 237838/237838 [00:00<00:00, 718928.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index:0   ['go'] -> [51]\n",
            "index:1   ['go'] -> [51]\n",
            "index:2   ['go'] -> [51]\n",
            "index:3   ['go'] -> [51]\n",
            "index:4   ['hi'] -> [2597]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sentences, max_len=None):\n",
        "  if max_len is None:\n",
        "    max_len = max([len(sentence) for sentence in sentences])\n",
        "  features = np.zeros((len(sentences),max_len),dtype=int)\n",
        "  for index, sentence in enumerate(sentences):\n",
        "    if len(sentence) !=0:\n",
        "      features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
        "  return features"
      ],
      "metadata": {
        "id": "6Gi665ZF-AjC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input)\n",
        "decoder_input = pad_sequences(decoder_input)\n",
        "decoder_target = pad_sequences(decoder_target)"
      ],
      "metadata": {
        "id": "-2KlRjKf_U39"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input.shape)\n",
        "print(decoder_input.shape)\n",
        "print(decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVdHLoR-_YMT",
        "outputId": "6a75de77-7773-467c-c245-c3b658d7b0c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237838, 65)\n",
            "(237838, 69)\n",
            "(237838, 69)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi4Wy48b_e_p",
        "outputId": "3d746a28-c5a9-486f-eabf-690f76e9e80a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 33175 198876 222265 ...  69374 171767 184765]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input= encoder_input[indices]\n",
        "decoder_input= decoder_input[indices]\n",
        "decoder_target= decoder_target[indices]"
      ],
      "metadata": {
        "id": "C3LHNJEG_dz-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([index_to_src[word] for word in encoder_input[6242]])\n",
        "print([index_to_tar[word] for word in decoder_input[6242]])\n",
        "print([index_to_tar[word] for word in decoder_target[6242]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7Vdhc2p_oNe",
        "outputId": "ae644579-4684-49ef-e945-527046fd1a90"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['we', 'need', 'to', 'get', 'you', 'out', 'of', 'here', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['<sos>', 'on', 'doit', 'vous', 'sortir', 'de', 'la', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['on', 'doit', 'vous', 'sortir', 'de', 'la', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val =int(100000*0.1)\n"
      ],
      "metadata": {
        "id": "7EfxCiIm_8n9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "6hxtlpa-BTsU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input_train.shape)\n",
        "print(decoder_input_train.shape)\n",
        "print(decoder_target_train.shape)\n",
        "print(encoder_input_test.shape)\n",
        "print(decoder_input_test.shape)\n",
        "print(decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwvTlmzpBfPI",
        "outputId": "1d26f076-ab2d-4469-813e-d36b1930191b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(227838, 65)\n",
            "(227838, 69)\n",
            "(227838, 69)\n",
            "(10000, 65)\n",
            "(10000, 69)\n",
            "(10000, 69)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "embadding_dim = 256\n",
        "hidden_units = 256"
      ],
      "metadata": {
        "id": "WWFDLZpsBNiZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    outputs, (hidden, cell) = self.lstm(x)\n",
        "    return outputs, hidden, cell"
      ],
      "metadata": {
        "id": "H-EIigWmBTId"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embedding_dim+hidden_units,hidden_units, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
        "    self.softmax=nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x, encoder_outputs, hidden, cell):\n",
        "    x = self.embedding(x)\n",
        "    attention_scores = torch.bmm(encoder_outputs, hidden.transpose(0,1).transpose(1,2))\n",
        "    attention_weights = self.softmax(attention_scores)\n",
        "    context_vector = torch.bmm(attention_weights.transpose(1,2), encoder_outputs)\n",
        "    seq_len= x.shape[1]\n",
        "    context_vecotr_repeated = context_vector.repeat(1, seq_len, 1)\n",
        "    x = torch.cat((x, context_vecotr_repeated), dim=2)\n",
        "    output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
        "    output=self.fc(output)\n",
        "\n",
        "    return output, hidden, cell"
      ],
      "metadata": {
        "id": "ruul3zuzCIyl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "        decoder_outputs, _, _ = self.decoder(trg, encoder_outputs, hidden, cell)\n",
        "        return decoder_outputs\n",
        "\n",
        "encoder = Encoder(src_vocab_size, embadding_dim, hidden_units)\n",
        "decoder = Decoder(tar_vocab_size, embadding_dim, hidden_units)\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "9jZioU-NDmTn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, dataloader, loss_function, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoder_input, decoder_input, decoder_target in dataloader:\n",
        "            encoder_input = encoder_input.to(device)\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            decoder_target = decoder_target.to(device)\n",
        "\n",
        "            outputs = model(encoder_input, decoder_input)\n",
        "            loss = loss_function(\n",
        "                outputs.view(-1, tar_vocab_size),\n",
        "                decoder_target.view(-1)\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            mask = decoder_target != 0  # padding 제외\n",
        "            preds = outputs.argmax(dim=2)\n",
        "            total_correct += (preds == decoder_target)[mask].sum().item()\n",
        "            total_count += mask.sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = total_correct / total_count if total_count > 0 else 0\n",
        "    model.train()  # 평가 후 다시 학습 모드로\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "dQldBq7hD7Bo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
        "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
        "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
        "\n",
        "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
        "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
        "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n",
        "\n",
        "batch_size = 128\n",
        "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "EVQuEcq5EBkf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs =50\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veZLdP0AEGF8",
        "outputId": "bc1d1d12-7a33-4167-d823-b7bc6a5c96c6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(16331, 256, padding_idx=0)\n",
              "    (lstm): LSTM(256, 256, batch_first=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(26065, 256, padding_idx=0)\n",
              "    (lstm): LSTM(512, 256, batch_first=True)\n",
              "    (fc): Linear(in_features=256, out_features=26065, bias=True)\n",
              "    (softmax): Softmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss =float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "\n",
        "  for encoder_input, decoder_input, decoder_target in train_dataloader:\n",
        "    encoder_input = encoder_input.to(device)\n",
        "    decoder_input = decoder_input.to(device)\n",
        "    decoder_target = decoder_target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(encoder_input, decoder_input)\n",
        "\n",
        "    loss= loss_function(outputs.view(-1, tar_vocab_size), decoder_target.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
        "  val_loss, val_acc = evaluation(model, test_dataloader, loss_function, device)\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}\")\n",
        "  print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "  if val_loss < best_val_loss:\n",
        "    best_val_loss = val_loss\n",
        "    torch.save(model.state_dict(), 'best_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "jB5D6JKgEQoO",
        "outputId": "7903628b-95cd-41ce-cb95-d77e58cbdc11"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Train Loss: 2.6561, Train Acc: 0.5007\n",
            "Epoch: 2\n",
            "Train Loss: 1.9738, Train Acc: 0.5904\n",
            "Epoch: 3\n",
            "Train Loss: 1.5802, Train Acc: 0.6477\n",
            "Epoch: 4\n",
            "Train Loss: 1.3108, Train Acc: 0.6917\n",
            "Epoch: 5\n",
            "Train Loss: 1.1171, Train Acc: 0.7287\n",
            "Epoch: 6\n",
            "Train Loss: 0.9863, Train Acc: 0.7535\n",
            "Epoch: 7\n",
            "Train Loss: 0.8737, Train Acc: 0.7776\n",
            "Epoch: 8\n",
            "Train Loss: 0.7915, Train Acc: 0.7941\n",
            "Epoch: 9\n",
            "Train Loss: 0.7184, Train Acc: 0.8111\n",
            "Epoch: 10\n",
            "Train Loss: 0.6653, Train Acc: 0.8223\n",
            "Epoch: 11\n",
            "Train Loss: 0.6124, Train Acc: 0.8338\n",
            "Epoch: 12\n",
            "Train Loss: 0.5707, Train Acc: 0.8439\n",
            "Epoch: 13\n",
            "Train Loss: 0.5371, Train Acc: 0.8512\n",
            "Epoch: 14\n",
            "Train Loss: 0.4961, Train Acc: 0.8613\n",
            "Epoch: 15\n",
            "Train Loss: 0.4712, Train Acc: 0.8668\n",
            "Epoch: 16\n",
            "Train Loss: 0.4446, Train Acc: 0.8734\n",
            "Epoch: 17\n",
            "Train Loss: 0.4190, Train Acc: 0.8794\n",
            "Epoch: 18\n",
            "Train Loss: 0.3984, Train Acc: 0.8842\n",
            "Epoch: 19\n",
            "Train Loss: 0.3804, Train Acc: 0.8879\n",
            "Epoch: 20\n",
            "Train Loss: 0.3599, Train Acc: 0.8934\n",
            "Epoch: 21\n",
            "Train Loss: 0.3448, Train Acc: 0.8970\n",
            "Epoch: 22\n",
            "Train Loss: 0.3296, Train Acc: 0.9009\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-192907676.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdecoder_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpu사용량때문에 Train ACC 0.9에서 멈춤"
      ],
      "metadata": {
        "id": "T1dOhhaAT5T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.to(device)\n",
        "\n",
        "val_loss, val_acc = evaluation(model, test_dataloader, loss_function, device)\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-H1VtDKEWOP",
        "outputId": "f0b7773c-aa47-437d-9591-a6f06a060c28"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.5729, Validation Acc: 0.6861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src ={v: k for k, v in src_vocab.items()}\n",
        "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
        "\n",
        "def seq_to_src(input_seq):\n",
        "  sentence=''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word!=0):\n",
        "      sentence=sentence+index_to_src[encoded_word]+' '\n",
        "  return sentence\n",
        "\n",
        "def seq_to_tar(input_seq):\n",
        "    sentence = ''\n",
        "    for encoded_word in input_seq:\n",
        "        if encoded_word != 0:  # 0은 패딩 제외\n",
        "            sentence += index_to_tar[encoded_word] + ' '\n",
        "    return sentence\n"
      ],
      "metadata": {
        "id": "3ycTmEt6EYNR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq, model, max_output_len, src_vocab, tar_vocab, index_to_tar, device):\n",
        "    model.eval()\n",
        "\n",
        "    sos_idx = tar_vocab['<sos>']\n",
        "    eos_idx = tar_vocab['<eos>']\n",
        "\n",
        "    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    encoder_outputs, hidden, cell = model.encoder(encoder_inputs)\n",
        "\n",
        "    decoder_input = torch.tensor([[sos_idx]], dtype=torch.long).to(device)\n",
        "\n",
        "    decoded_tokens = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_output_len):\n",
        "            output, hidden, cell = model.decoder(decoder_input, encoder_outputs, hidden, cell)\n",
        "            output_token = output.argmax(dim=-1).squeeze().item()\n",
        "\n",
        "            if output_token == eos_idx:\n",
        "                break\n",
        "\n",
        "            decoded_tokens.append(output_token)\n",
        "            decoder_input = torch.tensor([[output_token]], dtype=torch.long).to(device)\n",
        "\n",
        "    decoded_sentence = ' '.join(index_to_tar.get(token, '[UNK]') for token in decoded_tokens)\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "metadata": {
        "id": "vpCDYGIgEgu3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "    input_seq = encoder_input_train[seq_index]\n",
        "\n",
        "    translated_text = decode_sequence(\n",
        "        input_seq,\n",
        "        model,\n",
        "        max_output_len=20,\n",
        "        src_vocab=src_vocab,\n",
        "        tar_vocab=tar_vocab,\n",
        "        index_to_tar=index_to_tar,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(\"입력 문장:\", seq_to_src(encoder_input_train[seq_index]))\n",
        "    print(\"정답 문장:\", seq_to_tar(decoder_input_train[seq_index]))\n",
        "    print(\"번역 문장:\", translated_text)\n",
        "    print(\"=\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z9E3I3RzWxD",
        "outputId": "36430dbb-d6ac-46b6-a999-ed13f262a599"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: i haven t fully recovered yet \n",
            "정답 문장: <sos> je n ai pas encore completement recupere \n",
            "번역 문장: je n ai pas encore completement recupere\n",
            "==================================================\n",
            "입력 문장: tom waited his turn \n",
            "정답 문장: <sos> tom attendit son tour \n",
            "번역 문장: tom a attendu la peine d attente\n",
            "==================================================\n",
            "입력 문장: i fixed myself something to eat \n",
            "정답 문장: <sos> je me suis prepare quelque chose a manger \n",
            "번역 문장: je me suis fait quelque chose comme ca\n",
            "==================================================\n",
            "입력 문장: are you seriously thinking about buying that old car ? \n",
            "정답 문장: <sos> penses tu serieusement a acheter cette vieille guimbarde ? \n",
            "번역 문장: penses tu serieusement a vendre cette vieille guimbarde ?\n",
            "==================================================\n",
            "입력 문장: how dare you talk to my son like that ! \n",
            "정답 문장: <sos> comment oses tu parler a mon fils de cette facon ! \n",
            "번역 문장: comment oses tu parler a mon fils de cette facon\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "처리 실수 정답문장에 <sos>가 포함되게 됨"
      ],
      "metadata": {
        "id": "nWRgM2VMUAVz"
      }
    }
  ]
}